{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the data used in this project can be downloaded from: https://www.dropbox.com/s/cst9awcjpp08k33/50_categories.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "from skimage.io import imread\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Features from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(img_file):\n",
    "    \n",
    "    # read image\n",
    "    im_arr = imread(img_file)\n",
    "    \n",
    "    # check if image has only one color channel and if so stack the image three times to ensure that there are three\n",
    "    # (unfortunately) identical color channels\n",
    "    if len(im_arr.shape) == 2:\n",
    "        im_arr = np.dstack((im_arr, im_arr, im_arr))\n",
    "    \n",
    "    ## instatiate list (later to convert to array) to hold features\n",
    "    features = []\n",
    "    \n",
    "    # first do some dumb features:\n",
    "    \n",
    "    # calculate the mean in each color\n",
    "    color_means = im_arr.mean(axis=1).mean(axis=0)\n",
    "    \n",
    "    # use the ratio of maximum value in each color to the mean of each color\n",
    "    color_max_div_mean = im_arr.max(axis=1).max(axis=0) / color_means\n",
    "    features += list(color_max_div_mean)\n",
    "     \n",
    "    # use the ratio of standard deviations in each color to mean in each color as another set of features\n",
    "    color_std_div_mean = im_arr.std(axis=1).mean(axis=0) / color_means\n",
    "    features += list(color_std_div_mean)\n",
    "    \n",
    "    # use ratios of means, and correlation coefficients between flattened as additional features\n",
    "    mean_ratios = []\n",
    "    corr_coefs = []\n",
    "    for idx_pair in combinations(range(3), 2):\n",
    "        mean_ratios.append(color_means[idx_pair[0]] / color_means[idx_pair[1]])\n",
    "        corr_coefs.append(np.corrcoef(im_arr[:,:,idx_pair[0]].flatten(), im_arr[:,:,idx_pair[1]].flatten())[0,1])\n",
    "    features += mean_ratios + corr_coefs\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: gorilla\n",
      "Processing label: raccoon\n",
      "Processing label: crab\n",
      "Processing label: blimp\n",
      "Processing label: snail\n",
      "Processing label: airplanes\n",
      "Processing label: dog\n",
      "Processing label: dolphin\n",
      "Processing label: goldfish\n",
      "Processing label: giraffe\n",
      "Processing label: bear\n",
      "Processing label: killer-whale\n",
      "Processing label: penguin\n",
      "Processing label: zebra\n",
      "Processing label: duck\n",
      "Processing label: conch\n",
      "Processing label: camel\n",
      "Processing label: owl\n",
      "Processing label: helicopter\n",
      "Processing label: starfish\n",
      "Processing label: saturn\n",
      "Processing label: galaxy\n",
      "Processing label: goat\n",
      "Processing label: iguana\n",
      "Processing label: elk\n",
      "Processing label: hummingbird\n",
      "Processing label: triceratops\n",
      "Processing label: porcupine\n",
      "Processing label: teddy-bear\n",
      "Processing label: comet\n",
      "Processing label: hot-air-balloon\n",
      "Processing label: leopards\n",
      "Processing label: toad\n",
      "Processing label: mussels\n",
      "Processing label: kangaroo\n",
      "Processing label: speed-boat\n",
      "Processing label: bat\n",
      "Processing label: swan\n",
      "Processing label: octopus\n",
      "Processing label: frog\n",
      "Processing label: cormorant\n",
      "Processing label: unicorn\n",
      "Processing label: horse\n",
      "Processing label: skunk\n",
      "Processing label: mars\n",
      "Processing label: ostrich\n",
      "Processing label: goose\n",
      "Processing label: llama\n",
      "Processing label: snake\n",
      "Processing label: elephant\n"
     ]
    }
   ],
   "source": [
    "path = '50_categories/'\n",
    "\n",
    "# get labels\n",
    "labels = np.array([dr for dr in os.listdir(path) if '.DS_Store' not in dr])\n",
    "\n",
    "# process features\n",
    "X = []\n",
    "y = []\n",
    "for label in labels:\n",
    "    print('Processing label: {}'.format(label))\n",
    "    for fl in [fl for fl in os.listdir(path + label) if '.DS_Store' not in fl]:\n",
    "        X.append(feature_extract(path + label + '/' + fl))\n",
    "        y.append(label)\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.127208480565371"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine baseline\n",
    "d_clf = DummyClassifier(strategy='prior')\n",
    "d_clf.fit(X_train, y_train)\n",
    "d_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1696113074204947"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do random forest classification\n",
    "rf_clf = RandomForestClassifier(class_weight='balanced', random_state=100)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
