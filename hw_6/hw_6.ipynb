{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the data used in this project can be downloaded from: https://www.dropbox.com/s/cst9awcjpp08k33/50_categories.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature, filters\n",
    "from skimage.io import imread\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, zero_one_loss\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Features from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(img_file):\n",
    "    \n",
    "    # read image\n",
    "    im_arr = imread(img_file)\n",
    "    \n",
    "    # check if image has only one color channel and if so stack the image three times to ensure that there are three\n",
    "    # (unfortunately) identical color channels\n",
    "    if len(im_arr.shape) == 2:\n",
    "        im_arr = np.dstack((im_arr, im_arr, im_arr))\n",
    "    \n",
    "    ## instatiate list (later to convert to array) to hold features\n",
    "    features = []\n",
    "    \n",
    "    # first do some dumb features:\n",
    "    \n",
    "    # calculate the mean in each color\n",
    "    color_means = im_arr.mean(axis=1).mean(axis=0)\n",
    "    \n",
    "    # use the ratio of maximum value in each color to the mean of each color\n",
    "    color_max_div_mean = im_arr.max(axis=1).max(axis=0) / color_means\n",
    "    features += list(color_max_div_mean)\n",
    "     \n",
    "    # use the ratio of standard deviations in each color to mean in each color as another set of features\n",
    "    color_std_div_mean = im_arr.std(axis=1).mean(axis=0) / color_means\n",
    "    features += list(color_std_div_mean)\n",
    "    \n",
    "    # use ratios of means, and correlation coefficients between flattened as additional features\n",
    "    mean_ratios = []\n",
    "    corr_coefs = []\n",
    "    for idx_pair in combinations(range(3), 2):\n",
    "        mean_ratios.append(color_means[idx_pair[0]] / color_means[idx_pair[1]])\n",
    "        corr_coefs.append(np.corrcoef(im_arr[:,:,idx_pair[0]].flatten(), im_arr[:,:,idx_pair[1]].flatten())[0,1])\n",
    "    features += mean_ratios + corr_coefs\n",
    "    \n",
    "    # encode edge information\n",
    "    for i in range(3):\n",
    "        features.append(np.mean(filters.sobel(im_arr[:,:,i])))\n",
    "        features.append(np.mean(filters.sobel_v(im_arr[:,:,i])))\n",
    "        features.append(np.mean(filters.sobel_h(im_arr[:,:,i])))\n",
    "        \n",
    "    # encode segmentation information\n",
    "    features.append(felzenszwalb(im_arr).mean() / im_arr.mean())\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: gorilla\n",
      "Processing label: raccoon\n",
      "Processing label: crab\n",
      "Processing label: blimp\n",
      "Processing label: snail\n",
      "Processing label: airplanes\n",
      "Processing label: dog\n",
      "Processing label: dolphin\n",
      "Processing label: goldfish\n",
      "Processing label: giraffe\n",
      "Processing label: bear\n",
      "Processing label: killer-whale\n",
      "Processing label: penguin\n",
      "Processing label: zebra\n",
      "Processing label: duck\n",
      "Processing label: conch\n",
      "Processing label: camel\n",
      "Processing label: owl\n",
      "Processing label: helicopter\n",
      "Processing label: starfish\n",
      "Processing label: saturn\n",
      "Processing label: galaxy\n",
      "Processing label: goat\n",
      "Processing label: iguana\n",
      "Processing label: elk\n",
      "Processing label: hummingbird\n",
      "Processing label: triceratops\n",
      "Processing label: porcupine\n",
      "Processing label: teddy-bear\n",
      "Processing label: comet\n",
      "Processing label: hot-air-balloon\n",
      "Processing label: leopards\n",
      "Processing label: toad\n",
      "Processing label: mussels\n",
      "Processing label: kangaroo\n",
      "Processing label: speed-boat\n",
      "Processing label: bat\n",
      "Processing label: swan\n",
      "Processing label: octopus\n",
      "Processing label: frog\n",
      "Processing label: cormorant\n",
      "Processing label: unicorn\n",
      "Processing label: horse\n",
      "Processing label: skunk\n",
      "Processing label: mars\n",
      "Processing label: ostrich\n",
      "Processing label: goose\n",
      "Processing label: llama\n",
      "Processing label: snake\n",
      "Processing label: elephant\n"
     ]
    }
   ],
   "source": [
    "path = '50_categories/'\n",
    "\n",
    "# get labels\n",
    "labels = np.array([dr for dr in os.listdir(path) if '.DS_Store' not in dr])\n",
    "\n",
    "# process features\n",
    "X = []\n",
    "y = []\n",
    "for label in labels:\n",
    "    print('Processing label: {}'.format(label))\n",
    "    for fl in [fl for fl in os.listdir(path + label) if '.DS_Store' not in fl]:\n",
    "        X.append(feature_extract(path + label + '/' + fl))\n",
    "        y.append(label)\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and testing data\n",
    "X_tr_tmp, X_test_tmp, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# fit and scale training data\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_tr_tmp)\n",
    "\n",
    "# use scaling from training data to transform testing data\n",
    "X_test = X_scaler.transform(X_test_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14487632508833923"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine baseline\n",
    "d_clf = DummyClassifier(strategy='prior')\n",
    "d_clf.fit(X_train, y_train)\n",
    "d_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23910482921083628"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do random forest classification with default params\n",
    "rf_clf = RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=100)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28150765606595995"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do grid search over parameters with random forest classifier\n",
    "parameters = {'n_estimators': [10, 50, 150, 200, 300], 'max_depth': [10, 50, 100], 'min_samples_split': [2, 3, 4, 5]}\n",
    "cross_val = StratifiedKFold(n_splits=8, random_state = 100)\n",
    "gs = GridSearchCV(RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=100), parameters, cv = cross_val, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_class(clf, X_test, y_test):\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    print('Classification Metrics, between 0 and 1\\n')\n",
    "    \n",
    "    print('Accuracy Score: {:.3f}'.format(accuracy_score(y_test, pred)))\n",
    "    print('proportion of correct classifications - higher better\\n')\n",
    "    \n",
    "    print('Precision Score: {:.3f}'.format(precision_score(y_test, pred, average='weighted')))\n",
    "    print('tp / (tp + fp), how good at not having fp - higher better\\n')\n",
    "    \n",
    "    print('Recall Score: {:.3f}'.format(recall_score(y_test, pred, average='weighted')))\n",
    "    print('tp / (tp + fn), how good at finding positives - higher better\\n')\n",
    "    \n",
    "    print('Zero-One Loss: {:.3f}'.format(zero_one_loss(y_test, pred)))\n",
    "    print('fraction of misclassifications - smaller better')\n",
    "    \n",
    "    print('\\nFeature Importances: {}'.format(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics, between 0 and 1\n",
      "\n",
      "Accuracy Score: 0.239\n",
      "proportion of correct classifications - higher better\n",
      "\n",
      "Precision Score: 0.198\n",
      "tp / (tp + fp), how good at not having fp - higher better\n",
      "\n",
      "Recall Score: 0.239\n",
      "tp / (tp + fn), how good at finding positives - higher better\n",
      "\n",
      "Zero-One Loss: 0.761\n",
      "fraction of misclassifications - smaller better\n",
      "\n",
      "Feature Importances: [0.04494804 0.04647429 0.04719095 0.04680405 0.04236601 0.04590378\n",
      " 0.04984899 0.04678795 0.05229365 0.0479259  0.04438211 0.04630491\n",
      " 0.04270987 0.03983158 0.04199778 0.04423784 0.041179   0.04270349\n",
      " 0.04642514 0.03777494 0.04390861 0.05800111]\n"
     ]
    }
   ],
   "source": [
    "eval_class(rf_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics, between 0 and 1\n",
      "\n",
      "Accuracy Score: 0.282\n",
      "proportion of correct classifications - higher better\n",
      "\n",
      "Precision Score: 0.226\n",
      "tp / (tp + fp), how good at not having fp - higher better\n",
      "\n",
      "Recall Score: 0.282\n",
      "tp / (tp + fn), how good at finding positives - higher better\n",
      "\n",
      "Zero-One Loss: 0.718\n",
      "fraction of misclassifications - smaller better\n",
      "\n",
      "Feature Importances: [0.04553319 0.04703471 0.04502573 0.04430521 0.0451352  0.0462564\n",
      " 0.05085417 0.05002449 0.05180339 0.04927877 0.04613386 0.04608677\n",
      " 0.04404273 0.03835433 0.0393333  0.04533137 0.03802278 0.04018042\n",
      " 0.04509183 0.03764597 0.04435475 0.06017063]\n"
     ]
    }
   ],
   "source": [
    "eval_class(gs.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
