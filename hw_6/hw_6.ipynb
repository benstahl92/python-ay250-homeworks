{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the data used in this project can be downloaded from: https://www.dropbox.com/s/cst9awcjpp08k33/50_categories.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature, filters\n",
    "from skimage.io import imread\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.color import rgb2grey\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, zero_one_loss\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Features from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(img_file):\n",
    "    \n",
    "    # read image\n",
    "    im_arr = imread(img_file)\n",
    "    \n",
    "    # also get greyscale image to use for some of the feature extraction\n",
    "    gi = rgb2grey(im_arr)\n",
    "    \n",
    "    # check if image has only one color channel and if so stack the image three times to ensure that there are three\n",
    "    # (unfortunately) identical color channels\n",
    "    if len(im_arr.shape) == 2:\n",
    "        im_arr = np.dstack((im_arr, im_arr, im_arr))\n",
    "    \n",
    "    ## instatiate list (later to convert to array) to hold features\n",
    "    features = []\n",
    "    \n",
    "    # first do some dumb features:\n",
    "    \n",
    "    # calculate the mean in each color\n",
    "    color_means = im_arr.mean(axis=1).mean(axis=0)\n",
    "    \n",
    "    # use the ratio of maximum value in each color to the mean of each color\n",
    "    color_max_div_mean = im_arr.max(axis=1).max(axis=0) / color_means\n",
    "    features += list(color_max_div_mean)\n",
    "     \n",
    "    # use the ratio of standard deviations in each color to mean in each color as another set of features\n",
    "    color_std_div_mean = im_arr.std(axis=1).mean(axis=0) / color_means\n",
    "    features += list(color_std_div_mean)\n",
    "    \n",
    "    # use ratios of means, and correlation coefficients between flattened as additional features\n",
    "    mean_ratios = []\n",
    "    corr_coefs = []\n",
    "    for idx_pair in combinations(range(3), 2):\n",
    "        mean_ratios.append(color_means[idx_pair[0]] / color_means[idx_pair[1]])\n",
    "        corr_coefs.append(np.corrcoef(im_arr[:,:,idx_pair[0]].flatten(), im_arr[:,:,idx_pair[1]].flatten())[0,1])\n",
    "    features += mean_ratios + corr_coefs\n",
    "    \n",
    "    # encode edge information\n",
    "    for i in range(3):\n",
    "        features.append(np.mean(filters.sobel(im_arr[:,:,i])))\n",
    "        features.append(np.mean(filters.sobel_v(im_arr[:,:,i])))\n",
    "        features.append(np.mean(filters.sobel_h(im_arr[:,:,i])))\n",
    "        \n",
    "    # encode segmentation information\n",
    "    features.append(felzenszwalb(im_arr).mean() / im_arr.mean())\n",
    "    \n",
    "    # include proportion of edges detected in greyscale image relative to number of pixels\n",
    "    features.append(np.count_nonzero(feature.canny(gi)) / (np.shape(gi)[0] * np.shape(gi)[1]))\n",
    "    \n",
    "    # include ratio of max to mean of SIFT extracted features\n",
    "    tmp = feature.daisy(gi)\n",
    "    features.append(tmp.max() / tmp.mean())\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 ms ± 16.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "feature_extract('50_categories/bat/bat_0060.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing label: gorilla\n",
      "Processing label: raccoon\n",
      "Processing label: crab\n",
      "Processing label: blimp\n",
      "Processing label: snail\n",
      "Processing label: airplanes\n",
      "Processing label: dog\n",
      "Processing label: dolphin\n",
      "Processing label: goldfish\n",
      "Processing label: giraffe\n",
      "Processing label: bear\n",
      "Processing label: killer-whale\n",
      "Processing label: penguin\n",
      "Processing label: zebra\n",
      "Processing label: duck\n",
      "Processing label: conch\n",
      "Processing label: camel\n",
      "Processing label: owl\n",
      "Processing label: helicopter\n",
      "Processing label: starfish\n",
      "Processing label: saturn\n",
      "Processing label: galaxy\n",
      "Processing label: goat\n",
      "Processing label: iguana\n",
      "Processing label: elk\n",
      "Processing label: hummingbird\n",
      "Processing label: triceratops\n",
      "Processing label: porcupine\n",
      "Processing label: teddy-bear\n",
      "Processing label: comet\n",
      "Processing label: hot-air-balloon\n",
      "Processing label: leopards\n",
      "Processing label: toad\n",
      "Processing label: mussels\n",
      "Processing label: kangaroo\n",
      "Processing label: speed-boat\n",
      "Processing label: bat\n",
      "Processing label: swan\n",
      "Processing label: octopus\n",
      "Processing label: frog\n",
      "Processing label: cormorant\n",
      "Processing label: unicorn\n",
      "Processing label: horse\n",
      "Processing label: skunk\n",
      "Processing label: mars\n",
      "Processing label: ostrich\n",
      "Processing label: goose\n",
      "Processing label: llama\n",
      "Processing label: snake\n",
      "Processing label: elephant\n"
     ]
    }
   ],
   "source": [
    "path = '50_categories/'\n",
    "\n",
    "# get labels\n",
    "labels = np.array([dr for dr in os.listdir(path) if '.DS_Store' not in dr])\n",
    "\n",
    "# process features\n",
    "X = []\n",
    "y = []\n",
    "for label in labels:\n",
    "    print('Processing label: {}'.format(label))\n",
    "    for fl in [fl for fl in os.listdir(path + label) if '.DS_Store' not in fl]:\n",
    "        X.append(feature_extract(path + label + '/' + fl))\n",
    "        y.append(label)\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and testing data\n",
    "X_tr_tmp, X_test_tmp, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 100)\n",
    "\n",
    "# fit and scale training data\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_tr_tmp)\n",
    "\n",
    "# use scaling from training data to transform testing data\n",
    "X_test = X_scaler.transform(X_test_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.127208480565371"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine baseline\n",
    "d_clf = DummyClassifier(strategy='prior')\n",
    "d_clf.fit(X_train, y_train)\n",
    "d_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23439340400471143"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do random forest classification with default params\n",
    "rf_clf = RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=100)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28975265017667845"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do grid search over parameters with random forest classifier (note GridSearch provides access to best model by default when calling score/predict/etc)\n",
    "parameters = {'n_estimators': [10, 50, 150, 200, 300], 'max_depth': [10, 50, 100], 'min_samples_split': [2, 3, 4, 5]}\n",
    "cross_val = StratifiedKFold(n_splits=6, random_state = 100)\n",
    "gs = GridSearchCV(RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=100), parameters, cv = cross_val, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_class(clf, X_test, y_test):\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    print('Classification Metrics, between 0 and 1\\n')\n",
    "    \n",
    "    print('Accuracy Score: {:.3f}'.format(accuracy_score(y_test, pred)))\n",
    "    print('proportion of correct classifications - higher better\\n')\n",
    "    \n",
    "    print('Precision Score: {:.3f}'.format(precision_score(y_test, pred, average='weighted')))\n",
    "    print('tp / (tp + fp), how good at not having fp - higher better\\n')\n",
    "    \n",
    "    print('Recall Score: {:.3f}'.format(recall_score(y_test, pred, average='weighted')))\n",
    "    print('tp / (tp + fn), how good at finding positives - higher better\\n')\n",
    "    \n",
    "    print('Zero-One Loss: {:.3f}'.format(zero_one_loss(y_test, pred)))\n",
    "    print('fraction of misclassifications - smaller better')\n",
    "    \n",
    "    print('\\nFeature Importances: {}'.format(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics, between 0 and 1\n",
      "\n",
      "Accuracy Score: 0.234\n",
      "proportion of correct classifications - higher better\n",
      "\n",
      "Precision Score: 0.196\n",
      "tp / (tp + fp), how good at not having fp - higher better\n",
      "\n",
      "Recall Score: 0.234\n",
      "tp / (tp + fn), how good at finding positives - higher better\n",
      "\n",
      "Zero-One Loss: 0.766\n",
      "fraction of misclassifications - smaller better\n",
      "\n",
      "Feature Importances: [0.04397252 0.04172177 0.03912552 0.03808345 0.04085713 0.03825046\n",
      " 0.046497   0.04621291 0.04806991 0.04665511 0.04246693 0.04150559\n",
      " 0.03601019 0.03596632 0.04017705 0.0414116  0.03979764 0.03949712\n",
      " 0.03866133 0.03579007 0.04206483 0.05023433 0.04440413 0.04256707]\n"
     ]
    }
   ],
   "source": [
    "eval_class(rf_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Metrics, between 0 and 1\n",
      "\n",
      "Accuracy Score: 0.290\n",
      "proportion of correct classifications - higher better\n",
      "\n",
      "Precision Score: 0.254\n",
      "tp / (tp + fp), how good at not having fp - higher better\n",
      "\n",
      "Recall Score: 0.290\n",
      "tp / (tp + fn), how good at finding positives - higher better\n",
      "\n",
      "Zero-One Loss: 0.710\n",
      "fraction of misclassifications - smaller better\n",
      "\n",
      "Feature Importances: [0.04279333 0.04310368 0.04125217 0.03990932 0.03924309 0.04130955\n",
      " 0.04663581 0.04721613 0.04828333 0.04691954 0.0426583  0.0422816\n",
      " 0.03638974 0.03548245 0.03646901 0.03667754 0.0353029  0.03817309\n",
      " 0.03844805 0.03427391 0.04134137 0.05395202 0.04645035 0.04543372]\n"
     ]
    }
   ],
   "source": [
    "eval_class(gs.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pkl.dump({'model': gs, 'X_scaler': X_scaler}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Classifier for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_final_classifier(path, img_type = '.jpg', model_file = 'model.pkl', output_fname = 'predicted_classes.txt', return_arrays = False):\n",
    "    \n",
    "    # read model and scaler from model file\n",
    "    with open(model_file, 'rb') as f:\n",
    "        m = pkl.load(f)\n",
    "    model = m['model']\n",
    "    X_scaler = m['X_scaler']\n",
    "    \n",
    "    # do basic validation of provide path\n",
    "    if '/' != path[-1]:\n",
    "        path += '/'\n",
    "    \n",
    "    # get list of image files to classify\n",
    "    im_files = np.array([fl for fl in os.listdir(path) if img_type in fl])\n",
    "    \n",
    "    # get timing estimate\n",
    "    t1 = time.time()\n",
    "    feature_extract(path + im_files[0])\n",
    "    t2 = time.time()\n",
    "    dt = t2 - t1\n",
    "    \n",
    "    # do feature extraction\n",
    "    print('Extracting Features from {} images.'.format(len(im_files)))\n",
    "    X = []\n",
    "    for idx, fl in enumerate(im_files):\n",
    "        if idx % 50 == 0:\n",
    "            print('\\n\\tIteration: {} of {}'.format(idx, len(im_files)))\n",
    "            print('\\tEstimated Time Remaining: {:.1f} seconds'.format(dt * (len(im_files) - idx)))\n",
    "        X.append(feature_extract(path + fl))\n",
    "        \n",
    "    # scale X data\n",
    "    X = X_scaler.transform(np.array(X))\n",
    "    \n",
    "    # do classification\n",
    "    predicted_classes = model.predict(X)\n",
    "    \n",
    "    print('\\nClasses predicted, writing output to: {}'.format(output_fname))\n",
    "    \n",
    "    # write output file\n",
    "    with open(output_fname, 'w') as f:\n",
    "        f.write('{:<20} {}'.format('filename', 'predicted_class'))\n",
    "        f.write('-'*37)\n",
    "        for idx, fl in enumerate(im_files):\n",
    "            f.write('{:<20} {}'.format(fl, predicted_classes[idx]))\n",
    "            \n",
    "    # optionally return arrays\n",
    "    if return_arrays is True:\n",
    "        return im_files, predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features from 71 images.\n",
      "\n",
      "\tIteration: 0 of 71\n",
      "\tEstimated Time Remaining: 193.5 seconds\n",
      "\n",
      "\tIteration: 50 of 71\n",
      "\tEstimated Time Remaining: 57.2 seconds\n",
      "\n",
      "Classes predicted, writing output to: predicted_classes.txt\n"
     ]
    }
   ],
   "source": [
    "run_final_classifier('50_categories/bat/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
